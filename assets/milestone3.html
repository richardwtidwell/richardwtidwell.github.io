<article class="narrative">
  <h3>Milestone Three Narrative â€“ Algorithms & Data Structures</h3>
  <p>Richard Tidwell</p>
  <p>CS 499 Module Three Milestone</p>
  <p>The artifact is the search and listing subsystem of the Travlr application created in CS465. It exposes endpoints that read from a MongoDB collection of trips and present results to an admin client. For this milestone I enhanced the subsystem to demonstrate algorithms and data structure proficiency with measurable effects on latency and resource use. The scope covered the API layer, a small service layer, and supporting utilities and tests.</p>
  <p>I implemented a capacity bound LRU cache with TTL to reuse identical queries. Operations are O(1) using a Map and I export hits, misses, evictions, and set counts for tuning. I implemented a case insensitive prefix trie to power typeahead for trip codes and names. Insert is linear in word length and suggestion is O(k + r) where k is the prefix length and r is the number of results returned. Suggestions are produced with a lexical depth first walk for stable ordering and are capped to a fixed limit. The search endpoint applies server side pagination and compound sorting so work scales with page size rather than collection size. Short prefixes use trie candidates to narrow the query, while longer queries rely on database filters and indexes.</p>
  <p>I performed a focused repo audit and documented gaps in docs/algos/audit.md. I extended the trip schema with price, capacity, booked, tags, and a startDate alias, and I added indexes on code, name, startDate, plus a compound index on startDate and name. I introduced a repository and service layer with a stable cache key and periodic trie refresh. I added parameter validation, uniform JSON error envelopes, and rate limiting on the suggest endpoint. I normalized seed data and updated the admin UI to expose price, capacity, and booked so the client reflects the schema and endpoints. Unit tests cover the LRU and trie using node:test. A benchmark script records JSON for trie build and suggest timing and for LRU throughput and metrics. CI runs tests on Node 18 and Node 20. An .env.example documents cache capacity, cache TTL, and trie refresh intervals.</p>
  <p>This work meets outcome 3 by selecting structures with known complexity, bounding server work through pagination, and validating the approach with tests and benchmarks. It meets outcome 4 by applying sound techniques and tools that integrate cleanly with the existing codebase, including layered design, automated tests, benchmarks, and CI. It advances outcome 2 with an updated README, a concise audit, and consistent API contracts. It advances outcome 5 with input validation, bounded caches, capped page sizes and suggestion limits, and a rate limiter that mitigates abusive request patterns.</p>
  <p>I learned to prefer designs that produce predictable cost and to combine database indexing with in memory assistance only when the working set can be kept hot. Cache capacity, TTL, and key normalization must be tuned based on observed metrics rather than assumptions. The main challenges were stable suggestion ordering, result staleness, and parameter sweeps that attempt to create worst case behavior. I addressed these with lexical traversal and limits in the trie, periodic refresh and TTL in the cache, strict validation, and rate limiting. Remaining improvements include keyset pagination for deep offsets, pub or sub driven cache invalidation on writes, and optional fuzzy search using a BK tree if product needs justify it.</p>
</article>